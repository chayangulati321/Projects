{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imagePreprocessingUtils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f9e0d85e3cb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimagePreprocessingUtils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mipu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mCAPTURE_FLAG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imagePreprocessingUtils'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imagePreprocessingUtils as ipu\n",
    "\n",
    "CAPTURE_FLAG = False\n",
    "\n",
    "\n",
    "directory = input('Enter dataset directory name: ')\n",
    "\n",
    "exit = '**'\n",
    "\n",
    "try:\n",
    "    os.mkdir(directory)\n",
    "except:\n",
    "    print('Directory already exists!')\n",
    "    \n",
    "subDirectory = input('Enter sub directory name or press ** to exit: ')\n",
    "\n",
    "if subDirectory == exit:\n",
    "    print('exit')\n",
    "else:\n",
    "    path = directory + '/'+ subDirectory+ '/'\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        print('Sub directory already exists!')\n",
    "    \n",
    "    \n",
    "camera = cv2.VideoCapture(0)\n",
    "print('Now camera window will be open, then \\n1) Place your hand gesture in ROI and press c key to start capturing images . \\n2) Press esc key to exit.')\n",
    "\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    (t,frame) = camera.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    cv2.rectangle(frame,ipu.START, ipu.END,(0,255,0),2 )\n",
    "    # only for windows (remove lines 41 and 43 if you are using mac)\n",
    "    cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "    # please resize the window according to your screen.\n",
    "    cv2.resizeWindow('image', 1200,800)\n",
    "    ##\n",
    "    pressedKey = cv2.waitKey(1)\n",
    "    if pressedKey == 27:\n",
    "        break\n",
    "    elif pressedKey == ord('c'):\n",
    "        if(CAPTURE_FLAG):\n",
    "            CAPTURE_FLAG = False\n",
    "        else:\n",
    "            CAPTURE_FLAG = True\n",
    "    \n",
    "        # Region of Interest\n",
    "    if(CAPTURE_FLAG):\n",
    "        if(count<1200):\n",
    "            roi = frame[ ipu.START[1]+5:ipu.END[1], ipu.START[0]+5:ipu.END[0]]\n",
    "            cv2.imshow(\"Gesture\", roi)\n",
    "            frame = cv2.putText(frame, 'Capturing..', (50,70), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                   1.5, (0,255,0), 2, cv2.LINE_AA)\n",
    "            roi = cv2.resize(roi, (ipu.IMG_SIZE,ipu.IMG_SIZE))\n",
    "            cv2.imwrite(\"%s/%d.jpg\"%(path,count), roi)\n",
    "            count +=1\n",
    "            print(count)\n",
    "        else:\n",
    "            break\n",
    "    frame = cv2.putText(frame, str(count), (50,450), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                   2, (0,255,0), 2, cv2.LINE_AA)\n",
    "    #cv2.imshow(\"Video\",frame)\n",
    "    cv2.imshow('image',frame)\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "print('Completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imagePreprocessingUtils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-aeaa4cbcb344>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimagePreprocessingUtils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mipu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#import glob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imagePreprocessingUtils'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as skmetrics\n",
    "import random\n",
    "import pickle\n",
    "import imagePreprocessingUtils as ipu\n",
    "\n",
    "#import glob\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "def preprocess_all_images():\n",
    "    images_labels = []\n",
    "    train_disc_by_class = {}\n",
    "    test_disc_by_class = {}\n",
    "    all_train_dis = []\n",
    "    train_img_disc = []\n",
    "    test_img_disc = []\n",
    "    label_value = 0\n",
    "    for (dirpath,dirnames,filenames) in os.walk(ipu.PATH):\n",
    "        dirnames.sort()\n",
    "        for label in dirnames:\n",
    "            #print(label)\n",
    "            if not (label == '.DS_Store'):\n",
    "                for (subdirpath,subdirnames,images) in os.walk(ipu.PATH+'/'+label+'/'):\n",
    "                    #print(len(images))\n",
    "                    count = 0\n",
    "                    train_features = []\n",
    "                    test_features = []\n",
    "                    for image in images: \n",
    "                        #print(label)\n",
    "                        imagePath = ipu.PATH+'/'+label+'/'+image\n",
    "                        #print(imagePath)\n",
    "                        img = cv2.imread(imagePath)\n",
    "                        if img is not None:\n",
    "                            img = get_canny_edge(img)[0]\n",
    "                            sift_disc = get_SIFT_descriptors(img)\n",
    "                            print(sift_disc.shape)\n",
    "                            if(count < (ipu.TOTAL_IMAGES * ipu.TRAIN_FACTOR * 0.01)):\n",
    "                                print('Train:--------- Label is {} and Count is {}'.format(label, count)  )\n",
    "                                #train_features.append(sift_disc)\n",
    "                                train_img_disc.append(sift_disc)\n",
    "                                all_train_dis.extend(sift_disc)\n",
    "                                train_labels.append(label_value)\n",
    "                            elif((count>=(ipu.TOTAL_IMAGES * ipu.TRAIN_FACTOR  * 0.01)) and count <ipu.TOTAL_IMAGES):\n",
    "                                print('Test:--------- Label is {} and Count is {}'.format(label, count)  )\n",
    "                                #test_features.append(sift_disc)\n",
    "                                test_img_disc.append(sift_disc)\n",
    "                                test_labels.append(label_value)\n",
    "                            count += 1\n",
    "                        #images_labels.append((label,sift_disc))\n",
    "                #train_disc_by_class[label] = train_features\n",
    "                #test_disc_by_class[label] = test_features\n",
    "                label_value +=1\n",
    "                    \n",
    "    print('length of train features are %i' % len(train_img_disc))\n",
    "    print('length of test features are %i' % len(test_img_disc))\n",
    "    print('length of all train discriptors is {}'.format(len(all_train_dis)))\n",
    "    #print('length of all train discriptors by class  is {}'.format(len(train_disc_by_class)))\n",
    "    #print('length of all test disc is {}'.format(len(test_disc_by_class))) \n",
    "    return all_train_dis, train_img_disc, train_disc_by_class, test_disc_by_class, test_img_disc\n",
    "\n",
    "\n",
    "\n",
    "def get_canny_edge(image):\n",
    "   \n",
    "    grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert from RGB to HSV\n",
    "    HSVImaage = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) \n",
    "\n",
    "    # Finding pixels with itensity of skin\n",
    "    lowerBoundary = np.array([0,40,30],dtype=\"uint8\")\n",
    "    upperBoundary = np.array([43,255,254],dtype=\"uint8\")\n",
    "    skinMask = cv2.inRange(HSVImaage, lowerBoundary, upperBoundary)\n",
    "    \n",
    "    # blurring of gray scale using medianBlur\n",
    "    skinMask = cv2.addWeighted(skinMask,0.5,skinMask,0.5,0.0)\n",
    "    skinMask = cv2.medianBlur(skinMask, 5)\n",
    "    skin = cv2.bitwise_and(grayImage, grayImage, mask = skinMask)\n",
    "    #cv2.imshow(\"masked2\",skin)\n",
    "    \n",
    "    #. canny edge detection\n",
    "    canny = cv2.Canny(skin,60,60)\n",
    "    #plt.imshow(img2, cmap = 'gray')\n",
    "    return canny,skin\n",
    "\n",
    "def get_SIFT_descriptors(canny):\n",
    "    # Intialising SIFT\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    #surf.extended=True\n",
    "    canny = cv2.resize(canny,(256,256))\n",
    "    # computing SIFT descriptors\n",
    "    kp, des = surf.detectAndCompute(canny,None)\n",
    "    #print(len(des))\n",
    "    #sift_features_image = cv2.drawKeypoints(canny,kp,None,(0,0,255),4)\n",
    "    return des\n",
    "\n",
    "### K-means is not used as data is large and requires a better computer with good specifications\n",
    "def kmeans(k, descriptor_list):\n",
    "    print('K-Means started.')\n",
    "    print ('%i descriptors before clustering' % descriptor_list.shape[0])\n",
    "    kmeanss = KMeans(k)\n",
    "    kmeanss.fit(descriptor_list)\n",
    "    visual_words = kmeanss.cluster_centers_ \n",
    "    return visual_words, kmeanss\n",
    "\n",
    "def mini_kmeans(k, descriptor_list):\n",
    "    print('Mini batch K-Means started.')\n",
    "    print ('%i descriptors before clustering' % descriptor_list.shape[0])\n",
    "    kmeans_model = MiniBatchKMeans(k)\n",
    "    kmeans_model.fit(descriptor_list)\n",
    "    print('Mini batch K means trained to get visual words.')\n",
    "    filename = 'mini_kmeans_model.sav'\n",
    "    pickle.dump(kmeans_model, open(filename, 'wb'), protocol=2)\n",
    "    return kmeans_model\n",
    "\n",
    "\n",
    "def get_histograms(discriptors_by_class,visual_words, cluster_model):\n",
    "    histograms_by_class = {}\n",
    "    total_histograms = []\n",
    "    for label,images_discriptors in discriptors_by_class.items():\n",
    "        print('Label: %s' % label)\n",
    "        histograms = []\n",
    "        #    loop for all images \n",
    "        for each_image_discriptors in images_discriptors:\n",
    "            \n",
    "            ## manual method to calculate words occurence as histograms\n",
    "            '''histogram = np.zeros(len(visual_words))\n",
    "            # loop for all discriptors in a image discriptorss \n",
    "            for each_discriptor in each_image_discriptors:\n",
    "                #list_words = visual_words.tolist()\n",
    "                a = np.array([visual_words])\n",
    "                index = find_index(each_discriptor, visual_words)\n",
    "                #print(index)\n",
    "                #del list_words\n",
    "                histogram[index] += 1\n",
    "            print(histogram)'''\n",
    "            \n",
    "            ## using cluster model\n",
    "            raw_words = cluster_model.predict(each_image_discriptors)\n",
    "            hist =  np.bincount(raw_words, minlength=len(visual_words))\n",
    "            print(hist)\n",
    "            histograms.append(hist)\n",
    "        histograms_by_class[label] = histograms\n",
    "        total_histograms.append(histograms)\n",
    "    print('Histograms succesfully created for %i classes.' % len(histograms_by_class))\n",
    "    return histograms_by_class, total_histograms\n",
    "    \n",
    "def dataSplit(dataDictionary):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for key,values in dataDictionary.items():\n",
    "        for value in values:\n",
    "            X.append(value)\n",
    "            Y.append(key)\n",
    "    return X,Y\n",
    "        \n",
    "def predict_svm(X_train, X_test, y_train, y_test):\n",
    "    svc=SVC(kernel='linear') \n",
    "    print(\"Support Vector Machine started.\")\n",
    "    svc.fit(X_train,y_train)\n",
    "    filename = 'svm_model.sav'\n",
    "    pickle.dump(svc, open(filename, 'wb'), protocol=2)\n",
    "    y_pred=svc.predict(X_test)\n",
    "    np.savetxt('submission_svm.csv', np.c_[range(1,len(y_test)+1),y_pred,y_test], delimiter=',', header = 'ImageId,PredictedLabel,TrueLabel', comments = '', fmt='%d')\n",
    "    calculate_metrics(\"SVM\",y_test,y_pred)\n",
    "    \n",
    "\n",
    "def calculate_metrics(method,label_test,label_pred):\n",
    "    print(\"Accuracy score for \",method,skmetrics.accuracy_score(label_test,label_pred))\n",
    "    print(\"Precision_score for \",method,skmetrics.precision_score(label_test,label_pred,average='micro'))\n",
    "    print(\"f1 score for \",method,skmetrics.f1_score(label_test,label_pred,average='micro'))\n",
    "    print(\"Recall score for \",method,skmetrics.recall_score(label_test,label_pred,average='micro'))\n",
    "\n",
    "\n",
    "### STEP:1 SIFT discriptors for all train and test images with class seperation\n",
    "\n",
    "all_train_dis,train_img_disc, train_disc_by_class, test_disc_by_class, test_img_disc  = preprocess_all_images()\n",
    "\n",
    "##  deleting these variables as they are not used with mini batch k means\n",
    "del train_disc_by_class, test_disc_by_class \n",
    "\n",
    "### STEP:2 MINI K-MEANS \n",
    "\n",
    "mini_kmeans_model = mini_kmeans(ipu.N_CLASSES * ipu.CLUSTER_FACTOR, np.array(all_train_dis))\n",
    "\n",
    "del all_train_dis\n",
    "\n",
    "### Collecting VISUAL WORDS for all images (train , test)\n",
    "\n",
    "print('Collecting visual words for train .....')\n",
    "train_images_visual_words = [mini_kmeans_model.predict(visual_words) for visual_words in train_img_disc]\n",
    "print('Visual words for train data collected. length is %i' % len(train_images_visual_words))\n",
    "\n",
    "print('Collecting visual words for test .....')\n",
    "test_images_visual_words = [mini_kmeans_model.predict(visual_words) for visual_words in test_img_disc]\n",
    "print('Visual words for test data collected. length is %i' % len(test_images_visual_words))\n",
    "\n",
    "\n",
    "### STEP:3 HISTOGRAMS (findiing the occurence of each visual word of images in total words)\n",
    "## Can be calculated using get_histograms function also manually\n",
    "\n",
    "print('Calculating Histograms for train...')\n",
    "bovw_train_histograms = np.array([np.bincount(visual_words, minlength=ipu.N_CLASSES * ipu.CLUSTER_FACTOR) for visual_words in train_images_visual_words])\n",
    "print('Train histograms are collected. Length : %i ' % len(bovw_train_histograms))\n",
    "\n",
    "print('Calculating Histograms for test...')\n",
    "bovw_test_histograms = np.array([np.bincount(visual_words, minlength=ipu.N_CLASSES * ipu.CLUSTER_FACTOR) for visual_words in test_images_visual_words])\n",
    "print('Test histograms are collected. Length : %i ' % len(bovw_test_histograms))\n",
    "\n",
    "print('Each histogram length is : %i' % len(bovw_train_histograms[0]))\n",
    "#----------------------\n",
    "print('============================================')\n",
    "\n",
    "# preperaing for training svm\n",
    "X_train = bovw_train_histograms\n",
    "X_test = bovw_test_histograms\n",
    "Y_train = train_labels\n",
    "Y_test = test_labels\n",
    "\n",
    "#print(Y_train)\n",
    "### shuffling \n",
    "\n",
    "buffer  = list(zip(X_train, Y_train))\n",
    "random.shuffle(buffer)\n",
    "random.shuffle(buffer)\n",
    "random.shuffle(buffer)\n",
    "X_train, Y_train = zip(*buffer)\n",
    "#print(Y_train)\n",
    "\n",
    "buffer  = list(zip(X_test, Y_test))\n",
    "random.shuffle(buffer)\n",
    "random.shuffle(buffer)\n",
    "X_test, Y_test = zip(*buffer)\n",
    "\n",
    "print('Length of X-train:  %i ' % len(X_train))\n",
    "print('Length of Y-train:  %i ' % len(Y_train))\n",
    "print('Length of X-test:  %i ' % len(X_test))\n",
    "print('Length of Y-test:  %i ' % len(Y_test))\n",
    "\n",
    "predict_svm(X_train, X_test,Y_train, Y_test)\n",
    "\n",
    "\n",
    "#######################################################\n",
    "'''\n",
    "\n",
    "\n",
    "#STEP:2 K-MEANS clustering to get visual words \n",
    "\n",
    "visual_words, cluster_model = kmeans(ipu.N_CLASSES * 8, np.array(all_train_dis))\n",
    "\n",
    "print(' Length of Visual words using k-means= %i' % len(visual_words))\n",
    "print(type(visual_words))\n",
    "print(visual_words.shape)\n",
    "\n",
    "\n",
    "print('Histograms creation started for training set.')\n",
    "   \n",
    "bovw_train_histograms_by_class = get_histograms(train_disc_by_class,visual_words, cluster_model)[0]\n",
    "print('Histograms created with k-means.')\n",
    "\n",
    "\n",
    "for key, values in bovw_train_histograms_by_class.items():\n",
    "    for value in values:\n",
    "        print(value)\n",
    "   \n",
    "\n",
    "print('Histograms creation started for testing set.')\n",
    "bovw_test_histograms_by_class = get_histograms(test_disc_by_class,visual_words, cluster_model)[0]\n",
    "print('Histograms created.')\n",
    "\n",
    "X_train, Y_train = dataSplit(bovw_train_histograms_by_class)\n",
    "\n",
    "print('Length of x_train are % i ' % len(X_train))\n",
    "print('Length of y_train are % i ' % len(Y_train))\n",
    "\n",
    "X_test, Y_test = dataSplit(bovw_test_histograms_by_class)\n",
    "\n",
    "print('Length of x_test are % i ' % len(X_test))\n",
    "print('Length of y_test are % i ' % len(Y_test))\n",
    "\n",
    "\n",
    "X_train, Y_train = dataSplit(bovw_train_histograms_by_class)\n",
    "predict_svm(X_train, X_test,Y_train, Y_test)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imagePreprocessingUtils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-173463a08baa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimagePreprocessingUtils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mipu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imagePreprocessingUtils'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import imagePreprocessingUtils as ipu\n",
    "\n",
    "\n",
    "CAPTURE_FLAG = False\n",
    "\n",
    "class_labels = ipu.get_labels()\n",
    "                \n",
    "\n",
    "def recognise(cluster_model, classify_model):\n",
    "    global CAPTURE_FLAG\n",
    "    gestures = ipu.get_all_gestures()\n",
    "    cv2.imwrite(\"all_gestures.jpg\", gestures)\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    print('Now camera window will be open, then \\n1) Place your hand gesture in ROI (rectangle) \\n2) Press esc key to exit.')\n",
    "    count = 0\n",
    "    while(True):\n",
    "        (t,frame) = camera.read()\n",
    "        frame = cv2.flip(frame,1)\n",
    "        cv2.rectangle(frame,ipu.START, ipu.END,(0,255,0),2 )\n",
    "        cv2.imshow(\"All_gestures\", gestures)\n",
    "        pressedKey = cv2.waitKey(1)\n",
    "        if pressedKey == 27:\n",
    "            break\n",
    "        elif pressedKey == ord('p'):\n",
    "            if(CAPTURE_FLAG):\n",
    "                CAPTURE_FLAG = False\n",
    "            else:\n",
    "                CAPTURE_FLAG = True\n",
    "        if(CAPTURE_FLAG):\n",
    "            # Region of Interest\n",
    "            roi = frame[ ipu.START[1]+5:ipu.END[1], ipu.START[0]+5:ipu.END[0]]\n",
    "            if roi is not None:\n",
    "                roi = cv2.resize(roi, (ipu.IMG_SIZE,ipu.IMG_SIZE))\n",
    "                img = ipu.get_canny_edge(roi)[0]\n",
    "                cv2.imshow(\"Edges \",img)\n",
    "                print(img)\n",
    "                sift_disc = ipu.get_SIFT_descriptors(img)\n",
    "            print(type(sift_disc))\n",
    "            if sift_disc is not None:\n",
    "                visual_words = cluster_model.predict(sift_disc)\n",
    "                print('visual words collected.')\n",
    "                bovw_histogram = np.array(np.bincount(visual_words, minlength=ipu.N_CLASSES * ipu.CLUSTER_FACTOR))\n",
    "                pred = classify_model.predict([bovw_histogram])\n",
    "                label = class_labels[pred[0]]\n",
    "                rectangle_bgr = (0, 0, 0)\n",
    "                (text_width, text_height) = cv2.getTextSize('Predicted text:      ', 1, fontScale=1.5, thickness=2)[0]\n",
    "                # set the text start position\n",
    "                text_offset_x = 50\n",
    "                text_offset_y = 20\n",
    "                # make the coords of the box with a small padding of two pixels\n",
    "                box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 40, text_offset_y + text_height +50))\n",
    "                cv2.rectangle(frame, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED)\n",
    "                frame = cv2.putText(frame, 'Predicted text: ', (50,70), cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 2, cv2.LINE_AA)\n",
    "                frame = cv2.putText(frame, label, (300,80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "       \n",
    "        cv2.imshow(\"Video\",frame)\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "  \n",
    "    \n",
    "clustering_model = pickle.load(open('mini_kmeans_model.sav', 'rb'))    \n",
    "classification_model = pickle.load(open('svm_model.sav', 'rb'))\n",
    "recognise(clustering_model,classification_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
